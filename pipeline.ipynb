{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e825e18",
   "metadata": {},
   "source": [
    "\n",
    "## **Project Overview**\n",
    "**The purpose of this notebook is to ingest, clean, and transform five raw source files into four cleaned, standardized datasets.**\n",
    "\n",
    "This process includes:\n",
    "- Parsing and standardizing inconsistent fields (e.g., dates, phone numbers, emails)\n",
    "- Deduplicating records and ensuring referential integrity\n",
    "- Assigning unique identifiers to deals, companies, contacts, and marketing participants\n",
    "- Structuring the data into clean, relational tables ready for downstream analysis, reporting, or database ingestion\n",
    "- All functions used are defined in functions.py\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Deliverables**\n",
    "\n",
    "- **`deals_df`**: A clean list of deal opportunities with unique `Deal_IDs`\n",
    "- **`historical_financial_data_df`**: Historical EBITDA metrics linked by `Deal_ID`\n",
    "- **`companies_df`**: A master list of companies with unique `Company_IDs`\n",
    "- **`contacts_df`**: A cleaned list of contacts with unique `Contact_IDs`\n",
    "- **`marketing_participants_df`**: Event participants with unique `Participant_IDs` linked to `Contact_IDs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b80e9",
   "metadata": {},
   "source": [
    "Imports/Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba3b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import re\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be39b0",
   "metadata": {},
   "source": [
    "### Business Services Pipeline - Ingestion & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3dc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingesting Business Services Pipeline\n",
    "\n",
    "business_pipeline_df = pd.read_excel(\"/Users/sonamrupani/Desktop/Intapp Data Engineer Assessment - Data/data_files/Business Services Pipeline.xlsx\",\n",
    "                                     skiprows = 5,\n",
    "                                     usecols = \"A:V\")\n",
    "\n",
    "# leaving 'Date Added' out for additional date parsing/standardization\n",
    "bsp_dtypes = {\n",
    "    \"Company Name\": \"string\",\n",
    "    \"Project Name\": \"string\",\n",
    "    \"Investment Bank\": \"string\",\n",
    "    \"Banker\": \"string\",\n",
    "    \"Sourcing\": \"string\",\n",
    "    \"Transaction Type\": \"string\",\n",
    "    \"LTM Revenue\": \"Float64\",\n",
    "    \"LTM EBITDA\": \"Float64\",\n",
    "    \"2014A EBITDA\": \"Float64\",\n",
    "    \"2015A EBITDA\": \"Float64\",\n",
    "    \"2016A EBITDA\": \"Float64\",\n",
    "    \"2017A/E EBITDA\": \"Float64\",\n",
    "    \"2018E EBITDA\": \"Float64\",\n",
    "    \"Vertical\": \"string\",\n",
    "    \"Sub Vertical\": \"string\",\n",
    "    \"Enterprise Value\": \"Float64\",\n",
    "    \"Est. Equity Investment\": \"Float64\",\n",
    "    \"Status\": \"string\",\n",
    "    \"Current Owner\": \"string\",\n",
    "    \"Business Description\": \"string\",\n",
    "    \"Lead MD\": \"string\",\n",
    "    \"Notes\": \"string\" \n",
    "}\n",
    "\n",
    "#Financial columns to check\n",
    "bsp_financial_columns = [\n",
    "    \"LTM Revenue\",\n",
    "    \"LTM EBITDA\",\n",
    "    \"2014A EBITDA\",\n",
    "    \"2015A EBITDA\",\n",
    "    \"2016A EBITDA\",\n",
    "    \"2017A/E EBITDA\",\n",
    "    \"2018E EBITDA\",\n",
    "    \"Enterprise Value\",\n",
    "    \"Est. Equity Investment\"\n",
    "]\n",
    "\n",
    "#Cleansing white spaces and new lines\n",
    "business_pipeline_df = cleanse_column_names(business_pipeline_df)\n",
    "\n",
    "#Ensure proper null format - pd.NA\n",
    "business_pipeline_df = modernize_nans(business_pipeline_df)\n",
    "\n",
    "#Rename columns\n",
    "business_pipeline_df = business_pipeline_df.rename(columns={\"Invest. Bank\": \"Investment Bank\", \"Equity Investment Est.\": \"Est. Equity Investment\"})\n",
    "\n",
    "#TODO double check\n",
    "#hardcoding CAD to USD rate as 0.73\n",
    "business_deals, business_deals_audit_df= process_financial_dataframe(business_pipeline_df, bsp_financial_columns, cad_to_usd_rate=0.73)\n",
    "\n",
    "business_deals = business_deals.astype(bsp_dtypes)\n",
    "\n",
    "# 1. Backup original Date Added column\n",
    "business_deals[\"Date Added (Original)\"] = business_deals[\"Date Added\"]\n",
    "\n",
    "# 2. Apply the simple_date_parser function row-by-row\n",
    "business_deals[\"Date Added\"] = business_deals[\"Date Added (Original)\"].apply(date_parsing)\n",
    "\n",
    "display(business_deals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20397826",
   "metadata": {},
   "source": [
    "### Consumer Retail & Healthcare Pipeline - Ingestion & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af21acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_retail_healthcare_pipeline = pd.read_excel(\"Consumer Retail and Healthcare Pipeline.xlsx\",\\\n",
    "                                                    skiprows = 8, \\\n",
    "                                                    usecols = \"B:W\")\n",
    "\n",
    "#Cleansing white spaces and new lines\n",
    "consumer_retail_healthcare_pipeline = cleanse_column_names(consumer_retail_healthcare_pipeline)\n",
    "\n",
    "consumer_retail_healthcare_pipeline = modernize_nans(consumer_retail_healthcare_pipeline)\n",
    "\n",
    "#Excel formatting causing null trailing rows - remove\n",
    "consumer_retail_healthcare_pipeline = consumer_retail_healthcare_pipeline.dropna(subset=['Company Name'])\n",
    "cols = [col for col in consumer_retail_healthcare_pipeline.columns if col != 'Company Name']\n",
    "consumer_retail_healthcare_pipeline = consumer_retail_healthcare_pipeline[~consumer_retail_healthcare_pipeline[cols].isna().all(axis=1)]\n",
    "\n",
    "consumer_retail_health_deals = consumer_retail_healthcare_pipeline.copy()\n",
    "\n",
    "#Leave our dates for further processing\n",
    "crhp_dtypes = {\n",
    "    \"Company Name\": \"string\",\n",
    "    \"Project Name\": \"string\",\n",
    "    \"Banker\": \"string\",\n",
    "    \"Banker Email\": \"string\",\n",
    "    \"Banker Phone Number\": \"string\",\n",
    "    \"Sourcing\": \"string\",\n",
    "    \"Transaction Type\": \"string\",\n",
    "    \"LTM Revenue\": \"Float64\",\n",
    "    \"LTM EBITDA\": \"Float64\",\n",
    "    \"Vertical\": \"string\",\n",
    "    \"Sub Vertical\": \"string\",\n",
    "    \"Enterprise Value\": \"Float64\",\n",
    "    \"Est. Equity Investment\": \"Float64\",\n",
    "    \"Status\": \"string\",\n",
    "    \"Portfolio Company Status\": \"string\",\n",
    "    \"Active Stage\": \"string\",\n",
    "    \"Passed Rationale\": \"string\",\n",
    "    \"Current Owner\": \"string\",\n",
    "    \"Business Description\": \"string\",\n",
    "    \"Lead MD\": \"string\",\n",
    "    \"Date Added\": \"datetime64[ns]\",\n",
    "    \"Date Added (Original)\": \"datetime64[ns]\",\n",
    "    \"Invest. Bank\": \"string\"\n",
    "}\n",
    "\n",
    "chrp_financial_cols = ['LTM Revenue', 'LTM EBITDA', 'Enterprise Value', 'Est. Equity Investment']\n",
    "\n",
    "consumer_retail_health_deals, crhp_audit_log = process_financial_dataframe(consumer_retail_health_deals, chrp_financial_cols)\n",
    "\n",
    "# 1. Backup original Date Added column\n",
    "consumer_retail_health_deals[\"Date Added (Original)\"] = consumer_retail_health_deals[\"Date Added\"]\n",
    "\n",
    "# 2. Apply the simple_date_parser function row-by-row\n",
    "consumer_retail_health_deals[\"Date Added\"] = consumer_retail_health_deals[\"Date Added (Original)\"].apply(date_parsing)\n",
    "\n",
    "consumer_retail_health_deals = update_data_types(consumer_retail_health_deals, crhp_dtypes)\n",
    "\n",
    "consumer_retail_health_deals = consumer_retail_health_deals.rename(columns = {\"Invest. Bank\": \"Investment Bank\"})\n",
    "\n",
    "display(consumer_retail_health_deals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d0acc",
   "metadata": {},
   "source": [
    "### Contacts - Ingest & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd9fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier_1_contacts = pd.read_excel(\"Contacts.xlsx\", sheet_name = \"Tier 1's\")\n",
    "tier_1_contacts[\"Tier\"] = 1\n",
    "\n",
    "tier_2_contacts = pd.read_excel(\"Contacts.xlsx\", sheet_name = \"Tier 2's\")\n",
    "tier_2_contacts[\"Tier\"] = 2\n",
    "\n",
    "contacts_df = pd.concat([tier_1_contacts, tier_2_contacts], ignore_index = True)\n",
    "\n",
    "#Cleansing white spaces and new lines\n",
    "contacts_df = cleanse_column_names(contacts_df)\n",
    "\n",
    "contacts_df = modernize_nans(contacts_df)\n",
    "\n",
    "contacts_dtypes = {\n",
    "    \"Firm\": \"string\",\n",
    "    \"Name\": \"string\",\n",
    "    \"Title\": \"string\",\n",
    "    \"Group\": \"string\",\n",
    "    \"Sub-Vertical\": \"string\",\n",
    "    \"E-mail\": \"string\",\n",
    "    \"Phone\": \"string\",\n",
    "    \"Secondary Phone\": \"string\",\n",
    "    \"City\": \"string\",\n",
    "    \"Coverage Person\": \"string\",\n",
    "    \"Preferred Contact Method\": \"string\"\n",
    "}\n",
    "\n",
    "contacts_df = update_data_types(contacts_df, contacts_dtypes)\n",
    "\n",
    "contacts_df['Birthday'] = pd.to_datetime(contacts_df['Birthday'])\n",
    "\n",
    "display(contacts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716122a0",
   "metadata": {},
   "source": [
    "### Events - Ingest & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e22ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaders_partners_events = pd.read_excel(\"Events.xlsx\", sheet_name = \"Leaders and Partners Dinner\")\n",
    "leaders_partners_events['Event'] = \"Leaders and Partners Dinner\"\n",
    "\n",
    "market_recap = pd.read_excel(\"Events.xlsx\", sheet_name=\"2019 Market Re-Cap\")\n",
    "market_recap['Event'] = \"2019 Market Re-Cap\"\n",
    "\n",
    "events_df = pd.concat([leaders_partners_events, market_recap], ignore_index=True)\n",
    "\n",
    "#Cleansing white spaces and new lines\n",
    "events_df = cleanse_column_names(events_df)\n",
    "\n",
    "events_df = modernize_nans(events_df)\n",
    "\n",
    "events_dtypes = {\n",
    "    \"Name\": \"string\",\n",
    "    \"E-mail\": \"string\",\n",
    "    \"Attendee Status\": \"string\",\n",
    "    \"Event\": \"string\"\n",
    "}\n",
    "\n",
    "events_df = update_data_types(events_df, events_dtypes)\n",
    "\n",
    "display(events_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc5fa0",
   "metadata": {},
   "source": [
    "### PE Comps - Ingest & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722373ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_companies = pd.read_excel(\"PE Comps.xlsx\",\n",
    "                             skiprows = 2,)\n",
    "\n",
    "#Dropping empty row between header and data\n",
    "pe_companies = pe_companies.drop(0)\n",
    "\n",
    "#Cleansing white spaces and new lines\n",
    "pe_companies = cleanse_column_names(pe_companies)\n",
    "\n",
    "pe_companies = modernize_nans(pe_companies)\n",
    "\n",
    "pe_companies['AUM(Mns)'] = pe_companies['AUM(Bns)'] * 1000\n",
    "\n",
    "pe_companies_dtypes = {\n",
    "    \"Priority\": \"string\", #empty, but keeping string for flexibility\n",
    "    \"Company Name\": \"string\",\n",
    "    \"Website\": \"string\",\n",
    "    \"Sectors\": \"string\",\n",
    "    \"Sample Portfolio Companies\": \"string\",\n",
    "    \"Contact Name 1\": \"string\",\n",
    "    \"Contact 2\": \"string\",\n",
    "    \"Comments\": \"string\",\n",
    "}\n",
    "\n",
    "pe_companies = update_data_types(pe_companies, pe_companies_dtypes)\n",
    "\n",
    "pe_companies = pe_companies.rename(columns = {\"Contact 2\": \"Contact Name 2\"})\n",
    "\n",
    "\n",
    "for col in pe_companies.columns:\n",
    "    pe_companies[col] = pe_companies[col].apply(clean_dash_text)\n",
    "\n",
    "pe_companies_df = pe_companies[[\n",
    "    \"Priority\", \n",
    "    \"Company Name\", \n",
    "    \"Website\", \n",
    "    \"AUM(Mns)\", \n",
    "    \"Sectors\", \n",
    "    \"Sample Portfolio Companies\", \n",
    "    \"Contact Name 1\",\n",
    "    \"Contact Name 2\",\n",
    "    \"Comments\"]]\n",
    "\n",
    "display(pe_companies_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f347f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL INGESTED AND CLEANED DATAFRAMES\n",
    "\n",
    "display(business_deals)\n",
    "display(consumer_retail_health_deals)\n",
    "display(contacts_df)\n",
    "display(events_df)\n",
    "display(pe_companies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166caf2e",
   "metadata": {},
   "source": [
    "### Data Modeling - Would make this into another portion of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c96d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understand cols to ensure proper joins\n",
    "print(f\"Business Deals: {business_deals.columns.tolist()}\")\n",
    "print(f\"Consumer Deals: {consumer_retail_health_deals.columns.tolist()}\")\n",
    "print(f\"Events DF: {events_df.columns.tolist()}\")\n",
    "print(f\"Contacts DF: {contacts_df.columns.tolist()}\")\n",
    "print(f\"PE Companies DF: {pe_companies_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATION OF DEALS DATASET\n",
    "\n",
    "#Removing historical EBITDA metrics, will be added into separate table\n",
    "business_deals = business_deals.reset_index(drop=True)\n",
    "business_deals['Deal_ID'] = business_deals.index.map(lambda x: f\"D{x+1:04d}\")\n",
    "\n",
    "#Table dedicated to historical financial metrics\n",
    "historical_financial_data_df = business_deals[[\n",
    "    \"Deal_ID\", \"Company Name\", \"Project Name\", \n",
    "    \"2014A EBITDA\", \"2015A EBITDA\", \"2016A EBITDA\", \"2017A/E EBITDA\", \"2018E EBITDA\"\n",
    "]]\n",
    "\n",
    "# create Deal_ID before segmenting into deals DF and financial history DF to allow for joins\n",
    "business_deals_df = business_deals[[\n",
    "    'Deal_ID', 'Company Name', 'Project Name', 'Date Added', 'Investment Bank', 'Banker',\n",
    "    'Sourcing', 'Transaction Type', 'LTM Revenue', 'LTM EBITDA', 'Vertical', 'Sub Vertical',\n",
    "    'Enterprise Value', 'Est. Equity Investment', 'Status', 'Current Owner', 'Business Description',\n",
    "    'Lead MD', 'Notes'\n",
    "]].copy()\n",
    "\n",
    "#Include missing columns from CRHP data. Will remain empty at the moment, but would normally work with client to find a way to populate\n",
    "business_deals_df['Banker Email'] = pd.Series(pd.NA, dtype='string')\n",
    "business_deals_df['Banker Phone Number'] = pd.Series(pd.NA, dtype='string')\n",
    "business_deals_df['Portfolio Company Status'] = pd.Series(pd.NA, dtype='string')\n",
    "business_deals_df['Active Stage'] = pd.Series(pd.NA, dtype='string')\n",
    "business_deals_df['Passed Rationale'] = pd.Series(pd.NA, dtype='string')\n",
    "\n",
    "#Create empty field for proper column references after concatenation\n",
    "consumer_retail_health_deals['Deal_ID'] = pd.Series(pd.NA, dtype='string')\n",
    "\n",
    "#Copy to preserve original cleaned dataframe\n",
    "consumer_deals_df = consumer_retail_health_deals[[\n",
    "    'Deal_ID', 'Company Name', 'Project Name', 'Date Added', 'Investment Bank', 'Banker', 'Banker Email',\n",
    "    'Banker Phone Number', 'Sourcing', 'Transaction Type', 'LTM Revenue', 'LTM EBITDA', 'Vertical',\n",
    "    'Sub Vertical', 'Enterprise Value', 'Est. Equity Investment', 'Status', 'Portfolio Company Status',\n",
    "    'Active Stage', 'Passed Rationale', 'Current Owner', 'Business Description', 'Lead MD', 'Notes'\n",
    "]].copy()\n",
    "\n",
    "#Concatenate the two\n",
    "deals_df = pd.concat([business_deals_df, consumer_deals_df], ignore_index=True)\n",
    "\n",
    "deals_df = deals_df.reset_index(drop=True)\n",
    "\n",
    "# Fill missing Deal_IDs\n",
    "deals_df['Deal_ID'] = deals_df.apply(\n",
    "    lambda row: row['Deal_ID'] if pd.notna(row['Deal_ID']) else f\"D{row.name+1:04d}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "deals_df = modernize_nans(deals_df)\n",
    "\n",
    "deals_df_reordered = desired_order = [\n",
    "    'Deal_ID', 'Company Name', 'Project Name', 'Date Added', 'Investment Bank', 'Banker',\n",
    "    'Sourcing', 'Transaction Type', 'LTM Revenue', 'LTM EBITDA', 'Vertical', 'Sub Vertical',\n",
    "    'Enterprise Value', 'Est. Equity Investment', 'Status', 'Current Owner', 'Business Description',\n",
    "    'Lead MD', 'Banker Email', 'Banker Phone Number', 'Portfolio Company Status', 'Active Stage',\n",
    "    'Passed Rationale', 'Notes'\n",
    "]\n",
    "\n",
    "deals_df = deals_df[deals_df_reordered]\n",
    "\n",
    "deals_df['Banker Phone Number'] = deals_df['Banker Phone Number'].apply(clean_phone)\n",
    "\n",
    "display(deals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea78502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPANIES DF\n",
    "\n",
    "pe_companies_subset = pe_companies_df[[\n",
    "    'Company Name',\n",
    "    'Website',\n",
    "    'AUM(Mns)',\n",
    "    'Sectors',\n",
    "    'Sample Portfolio Companies',\n",
    "    'Priority',\n",
    "    'Comments'\n",
    "]].copy()\n",
    " \n",
    "deals_companies_subset = deals_df[[\n",
    "    'Company Name',\n",
    "    'Business Description',\n",
    "    'Current Owner'\n",
    "]].copy()\n",
    "\n",
    "# Drop duplicates because same Company Name might appear in multiple deals\n",
    "deals_companies_subset = deals_companies_subset.drop_duplicates(subset='Company Name')\n",
    "\n",
    "#Normally would do an API call to look for certain fields like business description, current owner, website, sectors, sample portfolio companies\n",
    "companies_df = pd.merge(\n",
    "    deals_companies_subset,\n",
    "    pe_companies_subset,\n",
    "    how = \"outer\",\n",
    "    on = \"Company Name\"\n",
    ")\n",
    "\n",
    "#Clean up nulls\n",
    "companies_df = modernize_nans(companies_df)\n",
    "\n",
    "#Clean up after join\n",
    "companies_df = companies_df.dropna(how = \"all\")\n",
    "\n",
    "#Reset index\n",
    "companies_df = companies_df.reset_index(drop=True)\n",
    "\n",
    "#Create Company ID\n",
    "companies_df['Company_ID'] = companies_df.index.map(lambda x: f\"CO{x+1:04d}\")\n",
    "\n",
    "#Moving to first column\n",
    "cols = ['Company_ID'] + [col for col in companies_df.columns if col != 'Company_ID']\n",
    "companies_df = companies_df[cols]\n",
    "\n",
    "display(companies_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy\n",
    "contacts_df = contacts_df.copy()\n",
    "\n",
    "#Strip leading/trailing spaces\n",
    "contacts_df = contacts_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "#Clean Name (Title Case it)\n",
    "contacts_df['Name'] = contacts_df['Name'].apply(lambda x: x.title() if pd.notna(x) else x)\n",
    "\n",
    "#Clean Email (lowercase)\n",
    "contacts_df['Email'] = contacts_df['Email'].apply(lambda x: x.lower().strip() if pd.notna(x) else x)\n",
    "\n",
    "#Clean Phone numbers (remove non-numeric)\n",
    "contacts_df['Phone'] = contacts_df['Phone'].apply(clean_phone)\n",
    "contacts_df['Secondary Phone'] = contacts_df['Secondary Phone'].apply(clean_phone)\n",
    "\n",
    "#Clean Birthday\n",
    "contacts_df['Birthday'] = pd.to_datetime(contacts_df['Birthday'], errors='coerce')\n",
    "\n",
    "#Fill missing values\n",
    "contacts_df['Preferred Contact Method'] = contacts_df['Preferred Contact Method'].fillna('Email')\n",
    "\n",
    "#Reset index first\n",
    "contacts_df = contacts_df.reset_index(drop=True)\n",
    "\n",
    "#Create \n",
    "contacts_df['Contact_ID'] = contacts_df.index.map(lambda x: f\"C{x+1:04d}\")\n",
    "\n",
    "#Move Contact_ID to first column for cleanliness\n",
    "cols = ['Contact_ID'] + [col for col in contacts_df.columns if col != 'Contact_ID']\n",
    "contacts_df = contacts_df[cols]\n",
    "\n",
    "display(contacts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create marketing_participants_df\n",
    "marketing_participants_df = events_df.rename(columns={\n",
    "    'Name': 'Contact Name',\n",
    "    'E-mail': 'Email',\n",
    "    'Event': 'Event Name'\n",
    "}).copy()\n",
    "\n",
    "#Reset index\n",
    "marketing_participants_df = marketing_participants_df.reset_index(drop=True)\n",
    "\n",
    "#Create Participant_ID\n",
    "marketing_participants_df['Participant_ID'] = marketing_participants_df.index.map(lambda x: f\"M{x+1:04d}\")\n",
    "\n",
    "#Move ID to first column for cleanliness\n",
    "cols = ['Participant_ID'] + [col for col in marketing_participants_df.columns if col != 'Participant_ID']\n",
    "marketing_participants_df = marketing_participants_df[cols]\n",
    "\n",
    "#Lowercase and strip emails\n",
    "contacts_df['Email'] = contacts_df['Email'].str.lower().str.strip()\n",
    "marketing_participants_df['Email'] = marketing_participants_df['Email'].str.lower().str.strip()\n",
    "\n",
    "columns_to_drop = [col for col in marketing_participants_df.columns if 'Contact_ID' in col]\n",
    "if columns_to_drop:\n",
    "    marketing_participants_df = marketing_participants_df.drop(columns=columns_to_drop)\n",
    "\n",
    "#Merge Contact_ID onto marketing_participants_df - grab contact ID\n",
    "marketing_participants_df = marketing_participants_df.merge(\n",
    "    contacts_df[['Contact_ID', 'Email']],\n",
    "    on='Email',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#Reorder columns cleanly\n",
    "cols = ['Participant_ID', 'Contact_ID'] + [col for col in marketing_participants_df.columns if col not in ['Participant_ID', 'Contact_ID']]\n",
    "marketing_participants_df = marketing_participants_df[cols]\n",
    "\n",
    "#Reset index\n",
    "marketing_participants_df = marketing_participants_df.reset_index(drop=True)\n",
    "\n",
    "display(marketing_participants_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f60296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final outputs\n",
    "deals_df.to_excel('final_deals.xlsx', index=False)\n",
    "historical_financial_data_df.to_excel('final_financial_data.xlsx', index=False)\n",
    "companies_df.to_excel('final_companies.xlsx', index=False)\n",
    "contacts_df.to_excel('final_contacts.xlsx', index=False)\n",
    "marketing_participants_df.to_excel('final_marketing_participants.xlsx', index=False)\n",
    "\n",
    "print(\"All files saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
